{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTATION DE MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECTION AU FICHIER DE DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin de la BDD\n",
    "chemin = \"C:/Users/MOUSTAPHA BOYE/PROJETS AVEC VSCODE/Desgagnes/BDD 2024\"\n",
    "# Nom du fichier excel\n",
    "fichier = \"BDD_2024.xlsx\"\n",
    "# Chemin complet\n",
    "chemin_complet = f\"{chemin}/{fichier}\" \n",
    "# Chargement des données depuis un fichier Excel\n",
    "df = pd.read_excel(chemin_complet, sheet_name='Feuil1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 653 entries, 6 to 2655\n",
      "Data columns (total 61 columns):\n",
      " #   Column                              Non-Null Count  Dtype          \n",
      "---  ------                              --------------  -----          \n",
      " 0   Ident_Pavillon                      653 non-null    object         \n",
      " 1   Ident_Type                          653 non-null    object         \n",
      " 2   Ident_Navire                        653 non-null    object         \n",
      " 3   Ident_Voyage                        653 non-null    int64          \n",
      " 4   Ident_CustomerReference             238 non-null    object         \n",
      " 5   Ident_Evenement                     653 non-null    object         \n",
      " 6   Position_Port_Latitude              652 non-null    object         \n",
      " 7   Position_Section_Longitude          349 non-null    object         \n",
      " 8   Position_Pays                       599 non-null    object         \n",
      " 9   Position_Code                       599 non-null    object         \n",
      " 10  Position_Province                   553 non-null    object         \n",
      " 11  Debut_Ancrage_Date                  653 non-null    object         \n",
      " 12  Debut_Ancrage_Heure                 653 non-null    object         \n",
      " 13  Fin_Ancrage_Date                    0 non-null      object         \n",
      " 14  Fin_Ancrage_Heure                   0 non-null      object         \n",
      " 15  Distance_Duree_h                    635 non-null    float64        \n",
      " 16  Distance_UTC                        653 non-null    object         \n",
      " 17  Distance_DateheureQuebec            653 non-null    datetime64[ns] \n",
      " 18  Distance_Capitaine                  652 non-null    float64        \n",
      " 19  Distance_Satellite                  294 non-null    float64        \n",
      " 20  Distance_Moy_Satellite              294 non-null    float64        \n",
      " 21  Distance_Priorisee                  324 non-null    float64        \n",
      " 22  Vitessecalcule                      635 non-null    float64        \n",
      " 23  ConsommationHFO_Bouilloire          219 non-null    float64        \n",
      " 24  ConsommationHFO_Chauffagecargaison  137 non-null    float64        \n",
      " 25  ConsommationHFO_EnginPrincipal      269 non-null    float64        \n",
      " 26  ConsommationHFO_EnginAuxiliaire     222 non-null    float64        \n",
      " 27  ConsommationHFO_Cargopumps          137 non-null    float64        \n",
      " 28  ConsommationHFO_Systemegazinterne   136 non-null    float64        \n",
      " 29  ConsommationMDO_Bouilloire          568 non-null    float64        \n",
      " 30  ConsommationMDO_Chauffagecargaison  312 non-null    float64        \n",
      " 31  ConsommationMDO_EnginPrincipal      560 non-null    float64        \n",
      " 32  ConsommationMDO_EnginAuxiliaire     591 non-null    float64        \n",
      " 33  ConsommationMDO_Cargopumps          308 non-null    float64        \n",
      " 34  ConsommationMDO_Systemegazinterne   318 non-null    float64        \n",
      " 35  ConsommationLNG_Bouilloire          227 non-null    float64        \n",
      " 36  ConsommationLNG_Chauffagecargaison  150 non-null    float64        \n",
      " 37  ConsommationLNG_EnginPrincipal      234 non-null    float64        \n",
      " 38  ConsommationLNG_EnginAuxiliaire     234 non-null    float64        \n",
      " 39  ConsommationLNG_Cargopumps          149 non-null    float64        \n",
      " 40  ConsommationLNG_Systemegazinterne   159 non-null    float64        \n",
      " 41  ROB_HFO                             653 non-null    float64        \n",
      " 42  ROB_MDO                             653 non-null    float64        \n",
      " 43  ROB_LNG                             653 non-null    float64        \n",
      " 44  Bunkering_BDNNumeroBonlivraison     0 non-null      object         \n",
      " 45  Bunkering_Carburant                 0 non-null      object         \n",
      " 46  Bunkering_Quantite                  0 non-null      float64        \n",
      " 47  Bunkering_Densite                   0 non-null      float64        \n",
      " 48  Bunkering_Souffre                   0 non-null      float64        \n",
      " 49  Bunkering_Valeurcalorifique         0 non-null      float64        \n",
      " 50  Position_Nom                        625 non-null    object         \n",
      " 51  Position_Pays.1                     585 non-null    object         \n",
      " 52  Position_Code.1                     585 non-null    object         \n",
      " 53  PositionETA_Date                    618 non-null    object         \n",
      " 54  PositionETA_Heure                   618 non-null    object         \n",
      " 55  PositionETD_Date                    609 non-null    object         \n",
      " 56  PositionETD_Heure                   609 non-null    object         \n",
      " 57  Position_                           621 non-null    object         \n",
      " 58  DiffTemps                           635 non-null    timedelta64[ns]\n",
      " 59  DiffTempsHeure                      635 non-null    float64        \n",
      " 60  MemeNavire                          653 non-null    bool           \n",
      "dtypes: bool(1), datetime64[ns](1), float64(32), int64(1), object(25), timedelta64[ns](1)\n",
      "memory usage: 311.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPRESSION DES COLONNES INUTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Ident_IDNavire\", \"BOSP_EOSP_Date\", \"BOSP_EOSP_Heure\", \"Gangwaydownandsecured_Date\",\n",
    "              \"SOF_Precision\", \"SOF_Commentaire\", \"SOF_Duree_h\", \"SOF_Cargo_MasseTM\", \"SOF_Cargo_VolumeM3\",\n",
    "              \"SOF_Forward\", \"SOF_Aft\", \"Gangwaydownandsecured_Heure\", \"DR_Distanceparcouru_24h\",\n",
    "              \"DR_Deviation\", \"DR_Vent\", \"DR_Meteo\", \"DR_Houle\", \"DR_Visibilite\", \"DR_Temps\", \"DR_Vitessemoycapitain_kts\",\n",
    "              \"DR_Cylindremoteurprincipal\", \"DR_Lubrificationmoteurprincipal\", \"DR_Lubrificationmoteursaux_\",\n",
    "              \"DR_Eaupotable\", \"DR_Eautechnique\", \"DR_Slopsbabord\", \"DR_Slopstribord\", \"DR_Autresresidushuileux\",\n",
    "              \"Equipage_CreerLe\", \"Equipage_CreerPar\", \"Equipage_Capitaine\", \"Equipage_1erOfficier\",\n",
    "              \"Equipage_Chefingenieur\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPRESSION DES VALEURS MANQUANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all')\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna(subset = ['Ident_Type'])\n",
    "df[df['Ident_Type'].isnull()]\n",
    "#supprimer les données avec les entêtes\n",
    "indexPavillon = df[df['Ident_Pavillon']=='Pavillon'].index\n",
    "df.drop(indexPavillon, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAITEMENT DES VALEURS MANQUANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Client Desgagnes / Unité d'affaires\n",
    "df['Ident_CustomerReference'] = df['Ident_CustomerReference'].fillna('Client_Inconnu')\n",
    "#Position des Navire\n",
    "df['Position_Port_Latitude'] = df['Position_Port_Latitude'].fillna('En Opération')\n",
    "df[['Position_Section_Longitude','Position_Pays','Position_Code','Position_Province']] = df[[\n",
    "    'Position_Section_Longitude','Position_Pays','Position_Code','Position_Province']].fillna('Missing')\n",
    "#Les valeurs manquantes sous condition d'une latitude non nulle\n",
    "df.loc[df['Position_Port_Latitude'].notna(),['Position_Pays','Position_Code','Position_Province'\n",
    "       ]] = df.loc[df['Position_Port_Latitude'].notna(),['Position_Pays','Position_Code',\n",
    "                  'Position_Province']].fillna('Missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPUTATION DES VALEURS MANQUANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputations des valeurs manquantes\n",
    "df.loc[df['Position_Port_Latitude'] == 'Cap Aux Meules', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','CMS','']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Cap Aux Meules', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','CMS','']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Cap Aux Meules', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','CMS','']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal ', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal ', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal ', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal ', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal 97', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal Norcan 74', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Montreal Suncor 109', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','MTR','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Tracy anchorage ', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','ST6','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Tracy Kildair Dock', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','ST6','QC']\n",
    "df.loc[df['Position_Port_Latitude'] == 'Trios Rivieres', ['Position_Pays', 'Position_Code','Position_Province']] = ['CA','TRR','QC']\n",
    "#Traitement de la distance priorisée\n",
    "df['Distance_Priorisee'] = df['Distance_Priorisee'].fillna(0)\n",
    "#Traitement des consommations\n",
    "df['ConsommationHFO_Bouilloire'] = df['ConsommationHFO_Bouilloire'].fillna(0)\n",
    "df['ConsommationHFO_Chauffagecargaison'] = df['ConsommationHFO_Chauffagecargaison'].fillna(0)\n",
    "df['ConsommationHFO_EnginPrincipal'] = df['ConsommationHFO_EnginPrincipal'].fillna(0)\n",
    "df['ConsommationHFO_EnginAuxiliaire'] = df['ConsommationHFO_EnginAuxiliaire'].fillna(0)\n",
    "df['ConsommationHFO_Cargopumps'] = df['ConsommationHFO_Cargopumps'].fillna(0)\n",
    "df['ConsommationHFO_Systemegazinterne'] = df['ConsommationHFO_Systemegazinterne'].fillna(0)\n",
    "df['ConsommationMDO_Bouilloire'] = df['ConsommationMDO_Bouilloire'].fillna(0)\n",
    "df['ConsommationMDO_Chauffagecargaison'] = df['ConsommationMDO_Chauffagecargaison'].fillna(0)\n",
    "df['ConsommationMDO_EnginPrincipal'] = df['ConsommationMDO_EnginPrincipal'].fillna(0)\n",
    "df['ConsommationMDO_Cargopumps'] = df['ConsommationMDO_Cargopumps'].fillna(0)\n",
    "df['ConsommationMDO_Systemegazinterne'] = df['ConsommationMDO_Systemegazinterne'].fillna(0)\n",
    "df['ConsommationLNG_Bouilloire'] = df['ConsommationLNG_Bouilloire'].fillna(0)\n",
    "df['ConsommationLNG_Chauffagecargaison'] = df['ConsommationLNG_Chauffagecargaison'].fillna(0)\n",
    "df['ConsommationLNG_EnginPrincipal'] = df['ConsommationLNG_EnginPrincipal'].fillna(0)\n",
    "df['ConsommationLNG_EnginAuxiliaire'] = df['ConsommationLNG_EnginAuxiliaire'].fillna(0)\n",
    "df['ConsommationLNG_Cargopumps'] = df['ConsommationLNG_Cargopumps'].fillna(0)\n",
    "df['ConsommationLNG_Systemegazinterne'] = df['ConsommationLNG_Systemegazinterne'].fillna(0)\n",
    "df['Bunkering_Quantite'] = df['Bunkering_Quantite'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# TRAITEMENT DE LA DATE ET HEURE ###############\n",
    "#Filtre des Evenements\n",
    "df = df[df['Ident_Evenement'].isin(['Arrival at port or position','Departure from port or position'])]\n",
    "\n",
    "df['Distance_DateheureQuebec'] = pd.to_datetime(df['Distance_DateheureQuebec'])\n",
    "#Trier les données\n",
    "df.sort_values(by=(['Ident_Navire','Distance_DateheureQuebec']))\n",
    "#Création d'une colonne temporaire pour les Evenements Arrivée et Départ\n",
    "#df['Temp_Event'] = df['Ident_Evenement'].where(df['Ident_Evenement'].isin(['Arrival at port or position','Departure from port or position']))\n",
    "#Calculer la différence de temps\n",
    "df['DiffTemps'] =  df['Distance_DateheureQuebec'] - df.groupby('Ident_Navire')['Distance_DateheureQuebec'].shift(1)\n",
    "# Convertir la différence de temps en une unité de mesure souhaitée, par exemple en minutes\n",
    "df['DiffTempsHeure'] = df['DiffTemps'].dt.total_seconds() / 3600\n",
    "# Créer une colonne pour vérifier si la ligne actuelle et la précédente appartiennent au même navire\n",
    "df['MemeNavire'] = df['Ident_Navire'] == df['Ident_Navire'].shift(1)\n",
    "# Mettre à NaN la différence de temps lorsqu'il ne s'agit pas du même navire\n",
    "df.loc[~df['MemeNavire'], 'DiffTempsHeure'] = np.nan\n",
    "df.to_excel('C:/Users/MOUSTAPHA BOYE/PROJETS AVEC VSCODE/Git_Desgagnes/Sorties/DiffTemps.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECTION DES VARIABLES POUR LA REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOUSTAPHA BOYE\\AppData\\Local\\Temp\\ipykernel_4232\\1427652374.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reg['Consommation_tot'] = df_reg[['ConsommationHFO_Bouilloire','ConsommationHFO_Chauffagecargaison',\n"
     ]
    }
   ],
   "source": [
    "colonnes = ['Ident_Pavillon','Ident_Type','Ident_Navire','Ident_Evenement','Distance_Duree_h',\n",
    "            'Distance_Priorisee','Vitessecalcule','ConsommationHFO_Bouilloire',\n",
    "            'ConsommationHFO_Chauffagecargaison','ConsommationHFO_EnginPrincipal','Bunkering_Quantite',\n",
    "            'ConsommationHFO_EnginAuxiliaire','ConsommationHFO_Cargopumps','ConsommationHFO_Systemegazinterne',\n",
    "            'ConsommationMDO_Bouilloire','ConsommationMDO_Chauffagecargaison','ConsommationMDO_EnginPrincipal',\n",
    "            'ConsommationMDO_EnginAuxiliaire','ConsommationMDO_Cargopumps','ConsommationMDO_Systemegazinterne',\n",
    "            'ConsommationLNG_Bouilloire','ConsommationLNG_Chauffagecargaison','ConsommationLNG_EnginPrincipal',\n",
    "            'ConsommationLNG_EnginAuxiliaire','ConsommationLNG_Cargopumps','ConsommationLNG_Systemegazinterne'\n",
    "]\n",
    "df_reg = df[colonnes]\n",
    "df_reg['Consommation_tot'] = df_reg[['ConsommationHFO_Bouilloire','ConsommationHFO_Chauffagecargaison',\n",
    "            'ConsommationHFO_EnginPrincipal','ConsommationLNG_Systemegazinterne','ConsommationHFO_EnginAuxiliaire',\n",
    "            'ConsommationHFO_Cargopumps','ConsommationHFO_Systemegazinterne','ConsommationMDO_Bouilloire',\n",
    "            'ConsommationMDO_Chauffagecargaison','ConsommationMDO_EnginPrincipal','ConsommationMDO_EnginAuxiliaire','ConsommationMDO_Cargopumps','ConsommationMDO_Systemegazinterne',\n",
    "            'ConsommationLNG_Bouilloire','ConsommationLNG_Chauffagecargaison','ConsommationLNG_EnginPrincipal',\n",
    "            'ConsommationLNG_EnginAuxiliaire','ConsommationLNG_Cargopumps']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION DE LA CONSOMMATION TOTALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur modèle trouvé: DecisionTreeRegressor avec un R² ajusté de 0.8976\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des variables nécessaires\n",
    "target_variable = 'Consommation_tot'\n",
    "\n",
    "# Suppression sécurisée des colonnes : l'argument errors='ignore' permet d'ignorer les colonnes non trouvées\n",
    "columns_to_drop = [target_variable,'ConsommationHFO_Bouilloire','ConsommationHFO_Chauffagecargaison',\n",
    "            'ConsommationHFO_EnginPrincipal','ConsommationLNG_Systemegazinterne','ConsommationHFO_EnginAuxiliaire',\n",
    "            'ConsommationHFO_Cargopumps','ConsommationHFO_Systemegazinterne','ConsommationMDO_Bouilloire',\n",
    "            'ConsommationMDO_Chauffagecargaison','ConsommationMDO_EnginPrincipal','ConsommationMDO_EnginAuxiliaire','ConsommationMDO_Cargopumps','ConsommationMDO_Systemegazinterne',\n",
    "            'ConsommationLNG_Bouilloire','ConsommationLNG_Chauffagecargaison','ConsommationLNG_EnginPrincipal',\n",
    "            'ConsommationLNG_EnginAuxiliaire','ConsommationLNG_Cargopumps']\n",
    "X = df_reg.drop(columns=columns_to_drop, errors='ignore')\n",
    "y = df_reg[target_variable]\n",
    "\n",
    "# Sélection des types de colonnes pour la transformation, en excluant les datetime\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Séparation des données en ensembles d'apprentissage et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuration du pipeline de prétraitement et de modélisation\n",
    "# Mise à jour du préprocesseur pour inclure SimpleImputer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())]), numerical_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder())]), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "models = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor(), SVR()]\n",
    "\n",
    "best_model = None\n",
    "best_r2_adjusted = -np.inf\n",
    "best_model_type = None\n",
    "\n",
    "# Boucle sur les différents modèles\n",
    "for model in models:\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1]\n",
    "    r2_adjusted = 1 - ((1-r2) * (n-1) / (n-p-1))\n",
    "    \n",
    "    if r2_adjusted > best_r2_adjusted:\n",
    "        best_model = pipeline\n",
    "        best_r2_adjusted = r2_adjusted\n",
    "        best_model_type = type(model).__name__\n",
    "\n",
    "if best_model:\n",
    "    print(f\"Meilleur modèle trouvé: {best_model_type} avec un R² ajusté de {best_r2_adjusted:.4f}\")\n",
    "        # Vérification pour les modèles linéaires avec 'coef_'\n",
    "    if hasattr(best_model.named_steps['model'], 'coef_'):\n",
    "        coefficients = best_model.named_steps['model'].coef_\n",
    "        \n",
    "        # Récupération des noms de fonctionnalités après l'encodage OneHot\n",
    "        # Nous appelons get_feature_names_out directement sur le ColumnTransformer après le pipeline a été ajusté\n",
    "        feature_names_out = best_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "        \n",
    "        # Préparation des noms de fonctionnalités finales en incluant les variables numériques et catégorielles\n",
    "        feature_names = feature_names_out\n",
    "        \n",
    "        # Création du DataFrame pour les coefficients avec les noms de fonctionnalités corrects\n",
    "        coeff_df = pd.DataFrame(coefficients.flatten(), index=feature_names, columns=['Coefficient'])\n",
    "        \n",
    "        # Exportation du DataFrame dans un fichier Excel\n",
    "        coeff_df.to_excel('C:/Users/MOUSTAPHA BOYE/PROJETS AVEC VSCODE/Coefficient_Regression_Best_Model.xlsx', sheet_name='Coefficients')\n",
    "        #df_final.to_excel('C:/Users/MOUSTAPHA BOYE/PROJETS AVEC VSCODE/BaseRegression.xlsx', sheet_name='Base')\n",
    "else:\n",
    "    print(\"Aucun modèle trouvé avec un R² ajusté supérieur à 95%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Position_Pays'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajout au depot GIT\n",
    "#git add .\n",
    "#git config --global core.autocrlf false\n",
    "#git commit -m \"Initial commit\"\n",
    "#git push -u origin master\n",
    "#git remote get-url origin verif url\n",
    "#git remote set-url origin https://github.com/nomUtilisateur/nomDepot.git définir le bon url\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
